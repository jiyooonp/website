<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>PaperMod on Jiyoon Park</title>
    <link>https://jiyooonp.github.io/posts/papermod.html</link>
    <description>Recent content in PaperMod on Jiyoon Park</description>
    <image>
      <url>https://jiyooonp.github.io/papermod-cover.png</url>
      <link>https://jiyooonp.github.io/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 22 Dec 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jiyooonp.github.io/posts/papermod/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>3D Reconstruction</title>
      <link>https://jiyooonp.github.io/posts/papermod/hw4.html</link>
      <pubDate>Thu, 22 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jiyooonp.github.io/posts/papermod/hw4.html</guid>
      <description>3D Reconstruction 16-720 Computer Vision: Homework 4 ¬∑ Fall 2022 üîóGITHUB About The Project Implemented an algorithm to reconstruct a 3D point cloud from a pair of images taken at different angles. Used the 8-point/7-point algorithm and triangulation to find and vizualize 3D locations of corresponding image points.
Built With: Python NumPy (back to top)
Results For the entire report, please refer to the Documentation
The Eight Point Algorithm for calculating the fundamental matrix The Seven Point Algorithm for calculating the fundamental matrix 3D Visualization of point cloud Bundle Adjustment using RANSAC Multi View Keypoint Reconstruction (back to top)</description>
    </item>
    
    <item>
      <title>Augmented Reality with Planar Homographies</title>
      <link>https://jiyooonp.github.io/posts/papermod/hw3.html</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jiyooonp.github.io/posts/papermod/hw3.html</guid>
      <description>Augmented Reality with Planar Homographies 16-720 Computer Vision: Homework 3 ¬∑ Fall 2022 üîóGITHUB About The Project Implementing an AR application step by step using planar homographies. Finding point correspondences between two images and use these to estimate the homography between them. Then using this homography to warp images and finally implement it on AR applications.
Built With: Python NumPy Results For the entire report, please refer to the Documentation</description>
    </item>
    
    <item>
      <title>Lucas-Kanade Tracking</title>
      <link>https://jiyooonp.github.io/posts/papermod/hw2.html</link>
      <pubDate>Sat, 22 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jiyooonp.github.io/posts/papermod/hw2.html</guid>
      <description>Lucas-Kanade Tracking 16-720 Computer Vision: Homework 2 ¬∑ Fall 2022 üîóGITHUB About The Project Implement asimple Lucas-Kanade (LK) tracker with a single template. And implement a motion subtraction method to track moving pixels in a scene. Finally, efficient tracking using inverse composition.
Built With: Python NumPy (back to top)
Results For the entire report, please refer to the Documentation
Lucas-Kanade Tracking with One Single Template Lucas-Kanade Tracking with Template Correction Moving Object Detection Track movement in video (back to top)</description>
    </item>
    
    <item>
      <title>Spatial Pyramid Matching for Scene Classification</title>
      <link>https://jiyooonp.github.io/posts/papermod/hw1.html</link>
      <pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jiyooonp.github.io/posts/papermod/hw1.html</guid>
      <description>Spatial Pyramid Matching for Scene Classification 16-720 Computer Vision: Homework 1 ¬∑ Fall 2022 üîóGITHUB About The Project Implementation of a scence classification system that uses bag-of-words approach with its spatial pyramid extenstion.
Built With: Python NumPy (back to top)
Pipeline Results For the entire report, please refer to the Documentation
Extracting Filter Responses Visualization of wordmaps 4 Building A Model of the Visual Word Final accuracy of classification (back to top)</description>
    </item>
    
    <item>
      <title>Camera Mobile Manipulator</title>
      <link>https://jiyooonp.github.io/posts/papermod/glab.html</link>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jiyooonp.github.io/posts/papermod/glab.html</guid>
      <description>üîóGITHUB Quick Start roslaunch cmm_gazebo ridgeback_iiwa_gazebo.launch roslaunch cmm_viz mobile_manipulation_interactive_demo.launch roslaunch darknet_ros darknet_ros.launch Visual Servoing Test in real world Manipulation Replication Test in real world Default World Darknet Camera Movement in Simulation LINKS Visual Servoing:
https://github.com/savnani5/Visual-Servoing/ Object Detection cpp:
https://docs.openvino.ai/latest/omz_demos_object_detection_demo_cpp.html RGBD Camera:
https://www.stereolabs.com/docs/ros/depth-sensing/ Gazebo person
- walking robot: http://gazebosim.org/tutorials?tut=actor&amp;amp;cat=build_robot TODO add RGBD camera instead of rgb camera move custom darknet to cmm_darknet make ridgebcak follow person Launch roslaunch cmm_gazebo ridgeback_iiwa_gazebo.launch roslaunch cmm_viz mobile_manipulation_interactive_demo.</description>
    </item>
    
    <item>
      <title>Ridgeback Trajectory Planning</title>
      <link>https://jiyooonp.github.io/posts/papermod/tsp.html</link>
      <pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jiyooonp.github.io/posts/papermod/tsp.html</guid>
      <description>üîóPROJECT PAGE &amp;nbsp;&amp;nbsp; üîóGITHUB Motivation: In taking our project to the next level, we wanted to allow our robot to draw on a large curved surface. This repository is for calculating the trajectory for following the curved wall.
--- Input: Mesh wall in .obj file form
Output: ridgeback trajectory
something like this:
X:-1.65, -0.86, -0.09, 1.64, 2.52, 3.6, 5.25, 5.27, 6.71, 7.09, 7.87, 9.79, 9.86 Y: -4.0, -4.34, -4.4, -4.</description>
    </item>
    
    <item>
      <title>JELP: Restaurant Recommendation and Analysis Website</title>
      <link>https://jiyooonp.github.io/posts/papermod/review.html</link>
      <pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jiyooonp.github.io/posts/papermod/review.html</guid>
      <description>JELP: Restaurant Recommendation and Analysis Website Big Data Application ¬∑ Fall 2021 üîóGITHUB About The Project Our Project JELP is a restaurant recommendation service that also provides useful information on restaurants. Our website cannot be accessed unless a user logs into the website. Once logged in, the user has access to all rank viewing, selecting, and viewing wanted data and data manipulation!
Built With: PHP SQLite HTML/CSS/JS Bootstrap Python Database Schema &amp;amp; ER diagram Overview of PHP Code Structure Demonstraion of website _</description>
    </item>
    
    <item>
      <title>Autonomous Driving Trolley, MEME</title>
      <link>https://jiyooonp.github.io/posts/papermod/capstone.html</link>
      <pubDate>Wed, 22 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jiyooonp.github.io/posts/papermod/capstone.html</guid>
      <description>Autonomous Driving Trolley, MEME üîóGITHUB
ÎãπÏã†Ïùò ÏáºÌïë ÏÉùÌôúÏùÑ upgradeÌï¥ Ï§Ñ MEME. Project Overview ‚Ä¢ How To Use ‚Ä¢ Contributors &amp; Blogs ‚Ä¢ References ‚Ä¢ Awards &amp; Patents ‚Ä¢ License Presentation Video ‚Ä¢ Paper ‚Ä¢ Poster ‚Ä¢ Notion ‚Ä¢ GitHub ‚ú® Project Overview ‚ÄºÔ∏è Key Features Object Tracking System with YOLOv5 &amp;amp; DeepSORT Keyword Spotting: RNN model on word &amp;ldquo;ÎØ∏ÎØ∏Ïïº&amp;rdquo; Realtime Location Track with LiDAR Sensor Emergency Detection with ultrasonic Sensor Embedding System ‚öíÔ∏è System Architecture üõéÔ∏è Quick Start Î≥∏ ÏãúÏä§ÌÖúÏùÄ Ubuntu 18.</description>
    </item>
    
    <item>
      <title>Course Information You Need</title>
      <link>https://jiyooonp.github.io/posts/papermod/ciyn.html</link>
      <pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://jiyooonp.github.io/posts/papermod/ciyn.html</guid>
      <description>CIYN | Course Information You Need Open Software Platform ¬∑ Fall 2020 üîó GITHUB About The Project Implementing an AR application step by step using planar homographies. Finding point correspondences between two images and use these to estimate the homography between them. Then using this homography to warp images and finally implement it on AR applications.
Page Configuration front-end-bootstrap folder has all elements of our site. front-end-prototype folder has the prototype images of our site.</description>
    </item>
    
  </channel>
</rss>
